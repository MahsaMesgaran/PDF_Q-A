{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q cassio datasets langchain openai tiktoken\n",
    "!pip install -q pycryptodome\n",
    "!pip install -q PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alternatvie text](https://miro.medium.com/v2/resize:fit:828/format:webp/1*jMAGouB3s_LA1YoslX5Z_A.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mahsa\\Langchain\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# libraris to connect to Cassendra db and perform tasks like text embeddings creating and storing vectors\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "# to wrap all thoes vectores in one specif package\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Support for dataset retrieval from Hugging Face\n",
    "from datasets import load_dataset\n",
    "\n",
    "# To integrate Astra Db in LAngchain, and initialize the DB  connection\n",
    "import cassio\n",
    "\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two first ids are used to connect to ASTRA DB, which has a cassandra db hosted over there in the cloud\n",
    "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:UX ...\"\n",
    "ASTRA_DB_ID = \"...\"\n",
    "\n",
    "OPENAI_API_KEY = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfreader = PdfReader(\"BudgetSpeech_2017.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to devide all our pdf contents into specific chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate\n",
    "\n",
    "raw_text = \"\"\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text += content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to initialize the connection to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ALngchain embeddings and LLM objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mahsa\\Langchain\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\mahsa\\Langchain\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LangChain Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create our vectore database. For that we need to initialize Cassandra. It converts all of the text using the embedding (that we initialized at the top cell) into vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_store = Cassandra(\n",
    "    embedding=embedding,\n",
    "    table_name=\"qa_demo\",\n",
    "    session=None,\n",
    "    keyspace=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still we haven't covert text to vectors. We need to push data inside DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# LLM models have a maximum token limit for the text they can process in one go. \n",
    "# We need to Split the text such that it should not increase the token limit.\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator= \"\\n\",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap = 200,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BUDGET SPEECH 2017\\nMuch of what I am going to relate to the House this afternoon was written at the height of the raging snowstorm \\nthat descended upon B.C. earlier this month. From my desk on the second floor of my old Matsqui Prairie farmhouse, I watched the blizzard unfold. \\nI watched the snowdrifts grow slowly, imperceptibly at first, until eventually my barn, my garage, and my parents’ \\nhouse all disappeared behind a 12-foot-high wall of snow. Doors were blocked shut. We were boxed in and cut off.\\nIt occurred to me that budgets and finances can take on a similar dynamic. Without careful attention to spending']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset into the vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding text, generating embeddings and inserting them inot Astra DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 50 headlines.\n"
     ]
    }
   ],
   "source": [
    "astra_vector_store.add_texts(texts[:50])\n",
    "\n",
    "print(\"Inserted %i headlines.\" %len(texts[:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wrap the entries inside the wrapper -> index w.r.t. text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two question examples from the pdf \"BudgetSpeech_2017.pdf\":\n",
    "\\\n",
    "Question1: what is the rank of B.C. among other provinces in terms of economic groth?\\\n",
    "Question2: what does Grand Chief Ed John recommended?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: \"what does Grand Chief Ed John recommended?\"\n",
      "\n",
      "ANSWER: \"He recommended that we continue and expand the \"Parents Legal Centre\" pilot project delivered by the Legal Services Society to provide early intervention services for families facing child protection concerns.\"\n",
      "\n",
      "First Documents by Relevance:\n",
      "    [0.9098] \"In his report, Grand Chief Ed John also recommended that we continue and expand the \n",
      "“Parents Legal  ...\"\n",
      "    [0.9098] \"In his report, Grand Chief Ed John also recommended that we continue and expand the \n",
      "“Parents Legal  ...\"\n",
      "    [0.9045] \"a move that will assist approximately 600 families and 1,000 children per year. As well, funding for ...\"\n",
      "    [0.9045] \"a move that will assist approximately 600 families and 1,000 children per year. As well, funding for ...\"\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "first_question = True\n",
    "while True:\n",
    "    if first_question:\n",
    "        query_text = input(\"\\nEnter your question or type 'quit' to exit: \").strip()\n",
    "    else:\n",
    "        query_text = input(\"\\nEnter your next question or type 'quit' to exit: \").strip()\n",
    "\n",
    "    if query_text.lower() == \"quit\":\n",
    "        break\n",
    "    if query_text == \"\":\n",
    "        continue\n",
    "\n",
    "    first_question = False\n",
    "\n",
    "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
    "    answer = astra_vector_index.query(query_text, llm = llm).strip()\n",
    "    print(\"\\nANSWER: \\\"%s\\\"\\n\" % answer)\n",
    "\n",
    "    print(\"First Documents by Relevance:\")\n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
    "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:100]))   #100 is number of characters we want to print out as answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
